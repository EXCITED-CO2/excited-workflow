{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b67b4b",
   "metadata": {},
   "source": [
    "This notebook reads in and masks the CarbonTracker and ERA data.\n",
    "\n",
    "It also rescales them to different spatial resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import netCDF4 as nc\n",
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa856824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Transcom Region boundaries\n",
    "\n",
    "filename_region = \"CarbonTracker\\\\regions.nc\" #this dataset contains the Transcom Region boundaries\n",
    "\n",
    "h = nc.Dataset(filename_region)\n",
    "transcom_regions = h.variables['transcom_regions'][:]\n",
    "\n",
    "# -- Close file\n",
    "h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc376c",
   "metadata": {},
   "source": [
    "This cell is creating a mask for 1 degree resolution data. This unmasks points that are in the North American temperate region (region 2 in the Transcom Regions dataset). \n",
    "\n",
    "This mask is for gridded ERA data which was downloaded in the range of: Latitude: (16,60), Longitude: (-135,-61)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adf33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a mask to be used for all our NA_temp region data\n",
    "\n",
    "NA_mask_1deg = np.ones((44,74)) #initially masking every element\n",
    "\n",
    "#function to convert from transcom coords to ERA coords (for my specific selection of coords in the data)\n",
    "def coords_change_1(lat, lon):\n",
    "    new_lat = (lat - 106)\n",
    "    new_lon = (lon - 45)\n",
    "    return(new_lat, new_lon)\n",
    "\n",
    "#unmasking the ERA datapoints which fall within the NA_temp region\n",
    "for lati in range( 106,150 ):\n",
    "    for longi in range( 45,119 ):\n",
    "        if transcom_regions[lati][longi] == 2:\n",
    "        \n",
    "            m_lat,m_lon = coords_change_1(lati,longi)\n",
    "            \n",
    "            NA_mask_1deg[m_lat][m_lon] = 0\n",
    "            \n",
    "NA_mask_1deg = np.repeat(NA_mask_1deg[np.newaxis, :, :], 12, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54823a1",
   "metadata": {},
   "source": [
    "This cell reads in the CarbonTracker data, storing each year separately.\n",
    "The '[:,106:150,45:119]' is there to extract the same subset as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aafac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the carbontracker bio_flux data \n",
    "#from 2000 to 2018\n",
    "\n",
    "carbon_path = 'CT2019B.flux1x1.'\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2000-monthly.nc\")\n",
    "bio_00 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_00 = np.ma.array(bio_00, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2001-monthly.nc\")\n",
    "bio_01 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_01 = np.ma.array(bio_01, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2002-monthly.nc\")\n",
    "bio_02 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_02 = np.ma.array(bio_02, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2003-monthly.nc\")\n",
    "bio_03 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_03 = np.ma.array(bio_03, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2004-monthly.nc\")\n",
    "bio_04 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_04 = np.ma.array(bio_04, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2005-monthly.nc\")\n",
    "bio_05 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_05 = np.ma.array(bio_05, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2006-monthly.nc\")\n",
    "bio_06 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_06 = np.ma.array(bio_06, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2007-monthly.nc\")\n",
    "bio_07 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_07 = np.ma.array(bio_07, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2008-monthly.nc\")\n",
    "bio_08 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_08 = np.ma.array(bio_08, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2009-monthly.nc\")\n",
    "bio_09 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_09 = np.ma.array(bio_09, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2010-monthly.nc\")\n",
    "bio_10 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_10 = np.ma.array(bio_10, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2011-monthly.nc\")\n",
    "bio_11 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_11 = np.ma.array(bio_11, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2012-monthly.nc\")\n",
    "bio_12 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_12 = np.ma.array(bio_12, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2013-monthly.nc\")\n",
    "bio_13 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_13 = np.ma.array(bio_13, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2014-monthly.nc\")\n",
    "bio_14 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_14 = np.ma.array(bio_14, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2015-monthly.nc\")\n",
    "bio_15 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_15 = np.ma.array(bio_15, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2016-monthly.nc\")\n",
    "bio_16 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_16 = np.ma.array(bio_16, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2017-monthly.nc\")\n",
    "bio_17 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_17 = np.ma.array(bio_17, mask = NA_mask_1deg )\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(carbon_path + \"2018-monthly.nc\")\n",
    "bio_18 = h.variables['bio_flux_opt'][:][:,106:150,45:119]\n",
    "bio_18 = np.ma.array(bio_18, mask = NA_mask_1deg )\n",
    "h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc27d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a mask to be used for all our NA_temp region data\n",
    "# this is converting the mask from 1deg resolution to 0.1 deg resolution\n",
    "\n",
    "NA_mask = np.ones((441,741)) #initially masking every element\n",
    "\n",
    "#function to convert from transcom coords to ERA coords (for my specific selection of coords in the data)\n",
    "def coords_change(lat, lon):\n",
    "    new_lat = 10*(lat - 106)\n",
    "    new_lon = 10*(lon - 45)\n",
    "    return(new_lat, new_lon)\n",
    "\n",
    "#unmasking the ERA datapoints which fall within the NA_temp region\n",
    "for lati in range( 106,150 ):\n",
    "    for longi in range( 45,119 ):\n",
    "        if transcom_regions[lati][longi] == 2:\n",
    "        \n",
    "            m_lat,m_lon = coords_change(lati,longi)\n",
    "            \n",
    "            #10 lons to the east\n",
    "            lats_to_access = list(range(m_lat,m_lat+10))\n",
    "            lats_to_access = [-1*element for element in lats_to_access]\n",
    "            \n",
    "            #10 lons east\n",
    "            NA_mask[lats_to_access , [m_lon]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+1]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+2]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+3]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+4]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+5]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+6]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+7]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+8]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+9]*10 ] = 0    \n",
    "            \n",
    "            #10 lons west\n",
    "            NA_mask[lats_to_access , [max(m_lon-1,0)]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-2,0)]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-3,0)]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-4,0)]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-5,0)]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-6,0)]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-7,0)]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-8,0)]*10 ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-9,0)]*10 ] = 0 \n",
    "            \n",
    "            #10 lats south\n",
    "            lats_to_access = list(range(max(0, m_lat-10),m_lat))\n",
    "            lats_to_access = [-1*element for element in lats_to_access]\n",
    "            \n",
    "            NA_mask[lats_to_access , [m_lon]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+1]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+2]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+3]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+4]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+5]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+6]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+7]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+8]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [m_lon+9]*len(lats_to_access) ] = 0    \n",
    "            \n",
    "            NA_mask[lats_to_access , [max(m_lon-1,0)]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-2,0)]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-3,0)]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-4,0)]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-5,0)]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-6,0)]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-7,0)]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-8,0)]*len(lats_to_access) ] = 0\n",
    "            NA_mask[lats_to_access , [max(m_lon-9,0)]*len(lats_to_access) ] = 0 \n",
    "            \n",
    "NA_mask_rep = np.repeat(NA_mask[np.newaxis, :, :], 12, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f00c1d",
   "metadata": {},
   "source": [
    "the np.flip and np.ma.array stuff is to mask the data properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting ERA data - 0.1 degree resolution\n",
    "\n",
    "filename_ERA = \"month_av_\"\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2000.nc')\n",
    "variable_00 = {}\n",
    "variable_00['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_00['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_00['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_00['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_00['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_00['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_00['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_00['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2001.nc')\n",
    "variable_01 = {}\n",
    "variable_01['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_01['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_01['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_01['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_01['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_01['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_01['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_01['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2002.nc')\n",
    "variable_02 = {}\n",
    "variable_02['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_02['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_02['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_02['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_02['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_02['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_02['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_02['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2003.nc')\n",
    "variable_03 = {}\n",
    "variable_03['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_03['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_03['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_03['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_03['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_03['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_03['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_03['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2004.nc')\n",
    "variable_04 = {}\n",
    "variable_04['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_04['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_04['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_04['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_04['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_04['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_04['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_04['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2005.nc')\n",
    "variable_05 = {}\n",
    "variable_05['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_05['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_05['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_05['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_05['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_05['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_05['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_05['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2006.nc')\n",
    "variable_06 = {}\n",
    "variable_06['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_06['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_06['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_06['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_06['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_06['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_06['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_06['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2007.nc')\n",
    "variable_07 = {}\n",
    "variable_07['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_07['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_07['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_07['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_07['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_07['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_07['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_07['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2008.nc')\n",
    "variable_08 = {}\n",
    "variable_08['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_08['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_08['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_08['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_08['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_08['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_08['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_08['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2009.nc')\n",
    "variable_09 = {}\n",
    "variable_09['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_09['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_09['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_09['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_09['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_09['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_09['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_09['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2010.nc')\n",
    "variable_10 = {}\n",
    "variable_10['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_10['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_10['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_10['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_10['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_10['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_10['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_10['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2011.nc')\n",
    "variable_11 = {}\n",
    "variable_11['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_11['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_11['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_11['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_11['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_11['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_11['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_11['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2012.nc')\n",
    "variable_12 = {}\n",
    "variable_12['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_12['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_12['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_12['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_12['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_12['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_12['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_12['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2013.nc')\n",
    "variable_13 = {}\n",
    "variable_13['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_13['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_13['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_13['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_13['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_13['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_13['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_13['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2014.nc')\n",
    "variable_14 = {}\n",
    "variable_14['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_14['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_14['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_14['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_14['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_14['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_14['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_14['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2015.nc')\n",
    "variable_15 = {}\n",
    "variable_15['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_15['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_15['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_15['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_15['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_15['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_15['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_15['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2016.nc')\n",
    "variable_16 = {}\n",
    "variable_16['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_16['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_16['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_16['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_16['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_16['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_16['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_16['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2017.nc')\n",
    "variable_17 = {}\n",
    "variable_17['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_17['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_17['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_17['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_17['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_17['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_17['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_17['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n",
    "\n",
    "h = nc.Dataset(filename_ERA + '2018.nc')\n",
    "variable_18 = {}\n",
    "variable_18['2 metre dewpoint temperature'] = np.flip(np.ma.array(h.variables['d2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_18['2 metre temperature'] = np.flip(np.ma.array(h.variables['t2m'][:], mask = NA_mask_rep ),1)\n",
    "variable_18['Surface latent heat flux'] = np.flip(np.ma.array(h.variables['slhf'][:], mask = NA_mask_rep ),1)\n",
    "variable_18['Surface net solar radiation'] = np.flip(np.ma.array(h.variables['ssr'][:], mask = NA_mask_rep ),1)\n",
    "variable_18['Surface net thermal radiation'] = np.flip(np.ma.array(h.variables['str'][:], mask = NA_mask_rep ),1)\n",
    "variable_18['Surface sensible heat flux'] = np.flip(np.ma.array(h.variables['sshf'][:], mask = NA_mask_rep ),1)\n",
    "variable_18['Surface pressure'] = np.flip(np.ma.array(h.variables['sp'][:], mask = NA_mask_rep ),1)\n",
    "variable_18['Total precipitation'] = np.flip(np.ma.array(h.variables['tp'][:], mask = NA_mask_rep ),1)\n",
    "h.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downscaling functions\n",
    "def downmean(array, n):\n",
    "    dim0 = array.shape[0]\n",
    "    dim1 = array.shape[1]\n",
    "    output = np.zeros(( dim0 // n , dim1 // n ))\n",
    "    for lati in range( dim0 // n ):\n",
    "        for longi in range( dim1 // n ):\n",
    "            output[lati,longi] = np.mean(array[n*lati:n*(lati+1),n*longi:n*(longi+1)])\n",
    "            \n",
    "    return output\n",
    "\n",
    "def downmean_3D(arr, n_0):\n",
    "    n = 10*n_0\n",
    "    \n",
    "    dim0 = arr.shape[0]\n",
    "    dim1 = arr.shape[1]\n",
    "    dim2 = arr.shape[2]\n",
    "    \n",
    "    output = np.zeros((dim0, dim1//n, dim2//n))\n",
    "    \n",
    "    for k,layer in enumerate(arr[:]):\n",
    "        output[k] = downmean(np.flip(layer,0),n)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def downmean_3D_mask(arr, n):\n",
    "    \n",
    "    dim0 = arr.shape[0]\n",
    "    dim1 = arr.shape[1]\n",
    "    dim2 = arr.shape[2]\n",
    "    \n",
    "    output = np.zeros((dim0, dim1//n, dim2//n))\n",
    "    \n",
    "    for k,layer in enumerate(arr[:]):\n",
    "        output[k] = downmean(np.flip(layer,0),n)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859239ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downscaling to ERA data to 1,3,5, and 10 degrees\n",
    "\n",
    "print('2000')\n",
    "deg1_00 = {}\n",
    "deg3_00 = {}\n",
    "deg5_00 = {}\n",
    "deg10_00 = {}\n",
    "for name,arra in variable_00.items():\n",
    "#     print(name)\n",
    "    deg1_00[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_00[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_00[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_00[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "\n",
    "print('2001')\n",
    "deg1_01 = {}\n",
    "deg3_01 = {}\n",
    "deg5_01 = {}\n",
    "deg10_01 = {}\n",
    "for name,arra in variable_01.items():\n",
    "#     print(name)\n",
    "    deg1_01[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_01[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_01[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_01[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2002')\n",
    "deg1_02 = {}\n",
    "deg3_02 = {}\n",
    "deg5_02 = {}\n",
    "deg10_02 = {}\n",
    "for name,arra in variable_02.items():\n",
    "#     print(name)\n",
    "    deg1_02[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_02[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_02[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_02[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2003')\n",
    "deg1_03 = {}\n",
    "deg3_03 = {}\n",
    "deg5_03 = {}\n",
    "deg10_03 = {}\n",
    "for name,arra in variable_03.items():\n",
    "#     print(name)\n",
    "    deg1_03[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_03[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_03[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_03[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2004')\n",
    "deg1_04 = {}\n",
    "deg3_04 = {}\n",
    "deg5_04 = {}\n",
    "deg10_04 = {}\n",
    "for name,arra in variable_04.items():\n",
    "#     print(name)\n",
    "    deg1_04[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_04[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_04[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_04[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2005')\n",
    "deg1_05 = {}\n",
    "deg3_05 = {}\n",
    "deg5_05 = {}\n",
    "deg10_05 = {}\n",
    "for name,arra in variable_05.items():\n",
    "#     print(name)\n",
    "    deg1_05[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_05[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_05[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_05[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2006')\n",
    "deg1_06 = {}\n",
    "deg3_06 = {}\n",
    "deg5_06 = {}\n",
    "deg10_06 = {}\n",
    "for name,arra in variable_06.items():\n",
    "#     print(name)\n",
    "    deg1_06[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_06[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_06[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_06[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2007')\n",
    "deg1_07 = {}\n",
    "deg3_07 = {}\n",
    "deg5_07 = {}\n",
    "deg10_07 = {}\n",
    "for name,arra in variable_07.items():\n",
    "#     print(name)\n",
    "    deg1_07[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_07[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_07[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_07[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2008')\n",
    "deg1_08 = {}\n",
    "deg3_08 = {}\n",
    "deg5_08 = {}\n",
    "deg10_08 = {}\n",
    "for name,arra in variable_08.items():\n",
    "#     print(name)\n",
    "    deg1_08[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_08[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_08[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_08[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2009')\n",
    "deg1_09 = {}\n",
    "deg3_09 = {}\n",
    "deg5_09 = {}\n",
    "deg10_09 = {}\n",
    "for name,arra in variable_09.items():\n",
    "#     print(name)\n",
    "    deg1_09[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_09[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_09[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_09[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2010')\n",
    "deg1_10 = {}\n",
    "deg3_10 = {}\n",
    "deg5_10 = {}\n",
    "deg10_10 = {}\n",
    "for name,arra in variable_10.items():\n",
    "#     print(name)\n",
    "    deg1_10[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_10[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_10[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_10[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2011')\n",
    "deg1_11 = {}\n",
    "deg3_11 = {}\n",
    "deg5_11 = {}\n",
    "deg10_11 = {}\n",
    "for name,arra in variable_11.items():\n",
    "#     print(name)\n",
    "    deg1_11[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_11[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_11[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_11[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2012')\n",
    "deg1_12 = {}\n",
    "deg3_12 = {}\n",
    "deg5_12 = {}\n",
    "deg10_12 = {}\n",
    "for name,arra in variable_12.items():\n",
    "#     print(name)\n",
    "    deg1_12[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_12[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_12[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_12[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2013')\n",
    "deg1_13 = {}\n",
    "deg3_13 = {}\n",
    "deg5_13 = {}\n",
    "deg10_13 = {}\n",
    "for name,arra in variable_13.items():\n",
    "#     print(name)\n",
    "    deg1_13[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_13[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_13[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_13[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2014')\n",
    "deg1_14 = {}\n",
    "deg3_14 = {}\n",
    "deg5_14 = {}\n",
    "deg10_14 = {}\n",
    "for name,arra in variable_14.items():\n",
    "#     print(name)\n",
    "    deg1_14[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_14[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_14[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_14[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2015')\n",
    "deg1_15 = {}\n",
    "deg3_15 = {}\n",
    "deg5_15 = {}\n",
    "deg10_15 = {}\n",
    "for name,arra in variable_15.items():\n",
    "#     print(name)\n",
    "    deg1_15[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_15[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_15[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_15[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2016')\n",
    "deg1_16 = {}\n",
    "deg3_16 = {}\n",
    "deg5_16 = {}\n",
    "deg10_16 = {}\n",
    "for name,arra in variable_16.items():\n",
    "#     print(name)\n",
    "    deg1_16[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_16[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_16[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_16[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2017')\n",
    "deg1_17 = {}\n",
    "deg3_17 = {}\n",
    "deg5_17 = {}\n",
    "deg10_17 = {}\n",
    "for name,arra in variable_17.items():\n",
    "#     print(name)\n",
    "    deg1_17[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_17[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_17[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_17[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n",
    "\n",
    "    \n",
    "print('2018')\n",
    "deg1_18 = {}\n",
    "deg3_18 = {}\n",
    "deg5_18 = {}\n",
    "deg10_18 = {}\n",
    "for name,arra in variable_18.items():\n",
    "#     print(name)\n",
    "    deg1_18[name] = np.ma.array(downmean_3D(np.flip(arra,1),1), mask = NA_mask_1deg)\n",
    "    deg3_18[name] = np.ma.array(downmean_3D(np.flip(arra,1),3), mask = NA_mask_3deg)\n",
    "    deg5_18[name] = np.ma.array(downmean_3D(np.flip(arra,1),5), mask = NA_mask_5deg)\n",
    "    deg10_18[name] = np.ma.array(downmean_3D(np.flip(arra,1),10), mask = NA_mask_10deg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biological flux at different resolutions:\n",
    "\n",
    "bio3_00 = np.ma.array(downmean_3D_mask(np.flip(bio_00,1), 3), mask = NA_mask_3deg)\n",
    "bio5_00 = np.ma.array(downmean_3D_mask(np.flip(bio_00,1), 5), mask = NA_mask_5deg)\n",
    "bio10_00 = np.ma.array(downmean_3D_mask(np.flip(bio_00,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_01 = np.ma.array(downmean_3D_mask(np.flip(bio_01,1), 3), mask = NA_mask_3deg)\n",
    "bio5_01 = np.ma.array(downmean_3D_mask(np.flip(bio_01,1), 5), mask = NA_mask_5deg)\n",
    "bio10_01 = np.ma.array(downmean_3D_mask(np.flip(bio_01,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_02 = np.ma.array(downmean_3D_mask(np.flip(bio_02,1), 3), mask = NA_mask_3deg)\n",
    "bio5_02 = np.ma.array(downmean_3D_mask(np.flip(bio_02,1), 5), mask = NA_mask_5deg)\n",
    "bio10_02 = np.ma.array(downmean_3D_mask(np.flip(bio_02,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_03 = np.ma.array(downmean_3D_mask(np.flip(bio_03,1), 3), mask = NA_mask_3deg)\n",
    "bio5_03 = np.ma.array(downmean_3D_mask(np.flip(bio_03,1), 5), mask = NA_mask_5deg)\n",
    "bio10_03 = np.ma.array(downmean_3D_mask(np.flip(bio_03,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_04 = np.ma.array(downmean_3D_mask(np.flip(bio_04,1), 3), mask = NA_mask_3deg)\n",
    "bio5_04 = np.ma.array(downmean_3D_mask(np.flip(bio_04,1), 5), mask = NA_mask_5deg)\n",
    "bio10_04 = np.ma.array(downmean_3D_mask(np.flip(bio_04,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_05 = np.ma.array(downmean_3D_mask(np.flip(bio_05,1), 3), mask = NA_mask_3deg)\n",
    "bio5_05 = np.ma.array(downmean_3D_mask(np.flip(bio_05,1), 5), mask = NA_mask_5deg)\n",
    "bio10_05 = np.ma.array(downmean_3D_mask(np.flip(bio_05,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_06 = np.ma.array(downmean_3D_mask(np.flip(bio_06,1), 3), mask = NA_mask_3deg)\n",
    "bio5_06 = np.ma.array(downmean_3D_mask(np.flip(bio_06,1), 5), mask = NA_mask_5deg)\n",
    "bio10_06 = np.ma.array(downmean_3D_mask(np.flip(bio_06,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_07 = np.ma.array(downmean_3D_mask(np.flip(bio_07,1), 3), mask = NA_mask_3deg)\n",
    "bio5_07 = np.ma.array(downmean_3D_mask(np.flip(bio_07,1), 5), mask = NA_mask_5deg)\n",
    "bio10_07 = np.ma.array(downmean_3D_mask(np.flip(bio_07,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_08 = np.ma.array(downmean_3D_mask(np.flip(bio_08,1), 3), mask = NA_mask_3deg)\n",
    "bio5_08 = np.ma.array(downmean_3D_mask(np.flip(bio_08,1), 5), mask = NA_mask_5deg)\n",
    "bio10_08 = np.ma.array(downmean_3D_mask(np.flip(bio_08,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_09 = np.ma.array(downmean_3D_mask(np.flip(bio_09,1), 3), mask = NA_mask_3deg)\n",
    "bio5_09 = np.ma.array(downmean_3D_mask(np.flip(bio_09,1), 5), mask = NA_mask_5deg)\n",
    "bio10_09 = np.ma.array(downmean_3D_mask(np.flip(bio_09,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_10 = np.ma.array(downmean_3D_mask(np.flip(bio_10,1), 3), mask = NA_mask_3deg)\n",
    "bio5_10 = np.ma.array(downmean_3D_mask(np.flip(bio_10,1), 5), mask = NA_mask_5deg)\n",
    "bio10_10 = np.ma.array(downmean_3D_mask(np.flip(bio_10,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_11 = np.ma.array(downmean_3D_mask(np.flip(bio_11,1), 3), mask = NA_mask_3deg)\n",
    "bio5_11 = np.ma.array(downmean_3D_mask(np.flip(bio_11,1), 5), mask = NA_mask_5deg)\n",
    "bio10_11 = np.ma.array(downmean_3D_mask(np.flip(bio_11,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_12 = np.ma.array(downmean_3D_mask(np.flip(bio_12,1), 3), mask = NA_mask_3deg)\n",
    "bio5_12 = np.ma.array(downmean_3D_mask(np.flip(bio_12,1), 5), mask = NA_mask_5deg)\n",
    "bio10_12 = np.ma.array(downmean_3D_mask(np.flip(bio_12,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_13 = np.ma.array(downmean_3D_mask(np.flip(bio_13,1), 3), mask = NA_mask_3deg)\n",
    "bio5_13 = np.ma.array(downmean_3D_mask(np.flip(bio_13,1), 5), mask = NA_mask_5deg)\n",
    "bio10_13 = np.ma.array(downmean_3D_mask(np.flip(bio_13,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_14 = np.ma.array(downmean_3D_mask(np.flip(bio_14,1), 3), mask = NA_mask_3deg)\n",
    "bio5_14 = np.ma.array(downmean_3D_mask(np.flip(bio_14,1), 5), mask = NA_mask_5deg)\n",
    "bio10_14 = np.ma.array(downmean_3D_mask(np.flip(bio_14,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_15 = np.ma.array(downmean_3D_mask(np.flip(bio_15,1), 3), mask = NA_mask_3deg)\n",
    "bio5_15 = np.ma.array(downmean_3D_mask(np.flip(bio_15,1), 5), mask = NA_mask_5deg)\n",
    "bio10_15 = np.ma.array(downmean_3D_mask(np.flip(bio_15,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_16 = np.ma.array(downmean_3D_mask(np.flip(bio_16,1), 3), mask = NA_mask_3deg)\n",
    "bio5_16 = np.ma.array(downmean_3D_mask(np.flip(bio_16,1), 5), mask = NA_mask_5deg)\n",
    "bio10_16 = np.ma.array(downmean_3D_mask(np.flip(bio_16,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_17 = np.ma.array(downmean_3D_mask(np.flip(bio_17,1), 3), mask = NA_mask_3deg)\n",
    "bio5_17 = np.ma.array(downmean_3D_mask(np.flip(bio_17,1), 5), mask = NA_mask_5deg)\n",
    "bio10_17 = np.ma.array(downmean_3D_mask(np.flip(bio_17,1), 10), mask = NA_mask_10deg)\n",
    "\n",
    "bio3_18 = np.ma.array(downmean_3D_mask(np.flip(bio_18,1), 3), mask = NA_mask_3deg)\n",
    "bio5_18 = np.ma.array(downmean_3D_mask(np.flip(bio_18,1), 5), mask = NA_mask_5deg)\n",
    "bio10_18 = np.ma.array(downmean_3D_mask(np.flip(bio_18,1), 10), mask = NA_mask_10deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdeb7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatteining arrays and turning into DataFrames with a 'year' column\n",
    "#Resolution: 1deg\n",
    "\n",
    "flat_00 = {}\n",
    "for name,arra in deg1_00.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_00[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_00.filled(np.nan).flatten()\n",
    "flat_00['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_00 = pd.DataFrame(flat_00)\n",
    "df_00['year'] = 2000\n",
    "\n",
    "flat_01 = {}\n",
    "for name,arra in deg1_01.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_01[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_01.filled(np.nan).flatten()\n",
    "flat_01['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_01= pd.DataFrame(flat_01)\n",
    "df_01['year'] = 2001\n",
    "\n",
    "flat_02 = {}\n",
    "for name,arra in deg1_02.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_02[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_02.filled(np.nan).flatten()\n",
    "flat_02['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_02 = pd.DataFrame(flat_02)\n",
    "df_02['year'] = 2002\n",
    "\n",
    "flat_03 = {}\n",
    "for name,arra in deg1_03.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_03[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_03.filled(np.nan).flatten()\n",
    "flat_03['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_03 = pd.DataFrame(flat_03)\n",
    "df_03['year'] = 2003\n",
    "\n",
    "flat_04 = {}\n",
    "for name,arra in deg1_04.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_04[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_04.filled(np.nan).flatten()\n",
    "flat_04['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_04 = pd.DataFrame(flat_04)\n",
    "df_04['year'] = 2004\n",
    "\n",
    "flat_05 = {}\n",
    "for name,arra in deg1_05.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_05[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_05.filled(np.nan).flatten()\n",
    "flat_05['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_05 = pd.DataFrame(flat_05)\n",
    "df_05['year'] = 2005\n",
    "\n",
    "flat_06 = {}\n",
    "for name,arra in deg1_06.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_06[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_06.filled(np.nan).flatten()\n",
    "flat_06['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_06 = pd.DataFrame(flat_06)\n",
    "df_06['year'] = 2006\n",
    "\n",
    "flat_07 = {}\n",
    "for name,arra in deg1_07.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_07[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_07.filled(np.nan).flatten()\n",
    "flat_07['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_07 = pd.DataFrame(flat_07)\n",
    "df_07['year'] = 2007\n",
    "\n",
    "flat_08 = {}\n",
    "for name,arra in deg1_08.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_08[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_08.filled(np.nan).flatten()\n",
    "flat_08['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_08 = pd.DataFrame(flat_08)\n",
    "df_08['year'] = 2008\n",
    "\n",
    "flat_09 = {}\n",
    "for name,arra in deg1_09.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_09[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_09.filled(np.nan).flatten()\n",
    "flat_09['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_09 = pd.DataFrame(flat_09)\n",
    "df_09['year'] = 2009\n",
    "\n",
    "flat_10 = {}\n",
    "for name,arra in deg1_10.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_10[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_10.filled(np.nan).flatten()\n",
    "flat_10['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_10 = pd.DataFrame(flat_10)\n",
    "df_10['year'] = 2010\n",
    "\n",
    "flat_11 = {}\n",
    "for name,arra in deg1_11.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_11[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_11.filled(np.nan).flatten()\n",
    "flat_11['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_11 = pd.DataFrame(flat_11)\n",
    "df_11['year'] = 2011\n",
    "\n",
    "flat_12 = {}\n",
    "for name,arra in deg1_12.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_12[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_12.filled(np.nan).flatten()\n",
    "flat_12['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_12 = pd.DataFrame(flat_12)\n",
    "df_12['year'] = 2012\n",
    "\n",
    "flat_13 = {}\n",
    "for name,arra in deg1_13.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_13[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_13.filled(np.nan).flatten()\n",
    "flat_13['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_13 = pd.DataFrame(flat_13)\n",
    "df_13['year'] = 2013\n",
    "\n",
    "flat_14 = {}\n",
    "for name,arra in deg1_14.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_14[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_14.filled(np.nan).flatten()\n",
    "flat_14['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_14 = pd.DataFrame(flat_14)\n",
    "df_14['year'] = 2014\n",
    "\n",
    "flat_15 = {}\n",
    "for name,arra in deg1_15.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_15[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_15.filled(np.nan).flatten()\n",
    "flat_15['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_15 = pd.DataFrame(flat_15)\n",
    "df_15['year'] = 2015\n",
    "\n",
    "flat_16 = {}\n",
    "for name,arra in deg1_16.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_16[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_16.filled(np.nan).flatten()\n",
    "flat_16['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_16 = pd.DataFrame(flat_16)\n",
    "df_16['year'] = 2016\n",
    "\n",
    "flat_17 = {}\n",
    "for name,arra in deg1_17.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_17[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_17.filled(np.nan).flatten()\n",
    "flat_17['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_17 = pd.DataFrame(flat_17)\n",
    "df_17['year'] = 2017\n",
    "\n",
    "flat_18 = {}\n",
    "for name,arra in deg1_18.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_18[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio_18.filled(np.nan).flatten()\n",
    "flat_18['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df_18 = pd.DataFrame(flat_18)\n",
    "df_18['year'] = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatteining arrays and turning into DataFrames with a 'year' column\n",
    "#Resolution: 3deg\n",
    "\n",
    "flat_00 = {}\n",
    "for name,arra in deg3_00.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_00[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_00.filled(np.nan).flatten()\n",
    "flat_00['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_00 = pd.DataFrame(flat_00)\n",
    "df3_00['year'] = 2000\n",
    "\n",
    "flat_01 = {}\n",
    "for name,arra in deg3_01.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_01[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_01.filled(np.nan).flatten()\n",
    "flat_01['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_01= pd.DataFrame(flat_01)\n",
    "df3_01['year'] = 2001\n",
    "\n",
    "flat_02 = {}\n",
    "for name,arra in deg3_02.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_02[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_02.filled(np.nan).flatten()\n",
    "flat_02['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_02 = pd.DataFrame(flat_02)\n",
    "df3_02['year'] = 2002\n",
    "\n",
    "flat_03 = {}\n",
    "for name,arra in deg3_03.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_03[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_03.filled(np.nan).flatten()\n",
    "flat_03['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_03 = pd.DataFrame(flat_03)\n",
    "df3_03['year'] = 2003\n",
    "\n",
    "flat_04 = {}\n",
    "for name,arra in deg3_04.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_04[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_04.filled(np.nan).flatten()\n",
    "flat_04['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_04 = pd.DataFrame(flat_04)\n",
    "df3_04['year'] = 2004\n",
    "\n",
    "flat_05 = {}\n",
    "for name,arra in deg3_05.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_05[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_05.filled(np.nan).flatten()\n",
    "flat_05['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_05 = pd.DataFrame(flat_05)\n",
    "df3_05['year'] = 2005\n",
    "\n",
    "flat_06 = {}\n",
    "for name,arra in deg3_06.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_06[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_06.filled(np.nan).flatten()\n",
    "flat_06['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_06 = pd.DataFrame(flat_06)\n",
    "df3_06['year'] = 2006\n",
    "\n",
    "flat_07 = {}\n",
    "for name,arra in deg3_07.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_07[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_07.filled(np.nan).flatten()\n",
    "flat_07['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_07 = pd.DataFrame(flat_07)\n",
    "df3_07['year'] = 2007\n",
    "\n",
    "flat_08 = {}\n",
    "for name,arra in deg3_08.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_08[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_08.filled(np.nan).flatten()\n",
    "flat_08['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_08 = pd.DataFrame(flat_08)\n",
    "df3_08['year'] = 2008\n",
    "\n",
    "flat_09 = {}\n",
    "for name,arra in deg3_09.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_09[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_09.filled(np.nan).flatten()\n",
    "flat_09['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_09 = pd.DataFrame(flat_09)\n",
    "df3_09['year'] = 2009\n",
    "\n",
    "flat_10 = {}\n",
    "for name,arra in deg3_10.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_10[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_10.filled(np.nan).flatten()\n",
    "flat_10['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_10 = pd.DataFrame(flat_10)\n",
    "df3_10['year'] = 2010\n",
    "\n",
    "flat_11 = {}\n",
    "for name,arra in deg3_11.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_11[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_11.filled(np.nan).flatten()\n",
    "flat_11['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_11 = pd.DataFrame(flat_11)\n",
    "df3_11['year'] = 2011\n",
    "\n",
    "flat_12 = {}\n",
    "for name,arra in deg3_12.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_12[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_12.filled(np.nan).flatten()\n",
    "flat_12['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_12 = pd.DataFrame(flat_12)\n",
    "df3_12['year'] = 2012\n",
    "\n",
    "flat_13 = {}\n",
    "for name,arra in deg3_13.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_13[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_13.filled(np.nan).flatten()\n",
    "flat_13['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_13 = pd.DataFrame(flat_13)\n",
    "df3_13['year'] = 2013\n",
    "\n",
    "flat_14 = {}\n",
    "for name,arra in deg3_14.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_14[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_14.filled(np.nan).flatten()\n",
    "flat_14['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_14 = pd.DataFrame(flat_14)\n",
    "df3_14['year'] = 2014\n",
    "\n",
    "flat_15 = {}\n",
    "for name,arra in deg3_15.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_15[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_15.filled(np.nan).flatten()\n",
    "flat_15['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_15 = pd.DataFrame(flat_15)\n",
    "df3_15['year'] = 2015\n",
    "\n",
    "flat_16 = {}\n",
    "for name,arra in deg3_16.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_16[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_16.filled(np.nan).flatten()\n",
    "flat_16['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_16 = pd.DataFrame(flat_16)\n",
    "df3_16['year'] = 2016\n",
    "\n",
    "flat_17 = {}\n",
    "for name,arra in deg3_17.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_17[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_17.filled(np.nan).flatten()\n",
    "flat_17['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_17 = pd.DataFrame(flat_17)\n",
    "df3_17['year'] = 2017\n",
    "\n",
    "flat_18 = {}\n",
    "for name,arra in deg3_18.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_18[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio3_18.filled(np.nan).flatten()\n",
    "flat_18['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df3_18 = pd.DataFrame(flat_18)\n",
    "df3_18['year'] = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500836bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatteining arrays and turning into DataFrames with a 'year' column\n",
    "#Resolution: 5deg\n",
    "\n",
    "flat_00 = {}\n",
    "for name,arra in deg5_00.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_00[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_00.filled(np.nan).flatten()\n",
    "flat_00['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_00 = pd.DataFrame(flat_00)\n",
    "df5_00['year'] = 2000\n",
    "\n",
    "flat_01 = {}\n",
    "for name,arra in deg5_01.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_01[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_01.filled(np.nan).flatten()\n",
    "flat_01['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_01= pd.DataFrame(flat_01)\n",
    "df5_01['year'] = 2001\n",
    "\n",
    "flat_02 = {}\n",
    "for name,arra in deg5_02.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_02[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_02.filled(np.nan).flatten()\n",
    "flat_02['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_02 = pd.DataFrame(flat_02)\n",
    "df5_02['year'] = 2002\n",
    "\n",
    "flat_03 = {}\n",
    "for name,arra in deg5_03.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_03[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_03.filled(np.nan).flatten()\n",
    "flat_03['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_03 = pd.DataFrame(flat_03)\n",
    "df5_03['year'] = 2003\n",
    "\n",
    "flat_04 = {}\n",
    "for name,arra in deg5_04.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_04[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_04.filled(np.nan).flatten()\n",
    "flat_04['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_04 = pd.DataFrame(flat_04)\n",
    "df5_04['year'] = 2004\n",
    "\n",
    "flat_05 = {}\n",
    "for name,arra in deg5_05.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_05[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_05.filled(np.nan).flatten()\n",
    "flat_05['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_05 = pd.DataFrame(flat_05)\n",
    "df5_05['year'] = 2005\n",
    "\n",
    "flat_06 = {}\n",
    "for name,arra in deg5_06.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_06[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_06.filled(np.nan).flatten()\n",
    "flat_06['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_06 = pd.DataFrame(flat_06)\n",
    "df5_06['year'] = 2006\n",
    "\n",
    "flat_07 = {}\n",
    "for name,arra in deg5_07.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_07[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_07.filled(np.nan).flatten()\n",
    "flat_07['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_07 = pd.DataFrame(flat_07)\n",
    "df5_07['year'] = 2007\n",
    "\n",
    "flat_08 = {}\n",
    "for name,arra in deg5_08.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_08[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_08.filled(np.nan).flatten()\n",
    "flat_08['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_08 = pd.DataFrame(flat_08)\n",
    "df5_08['year'] = 2008\n",
    "\n",
    "flat_09 = {}\n",
    "for name,arra in deg5_09.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_09[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_09.filled(np.nan).flatten()\n",
    "flat_09['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_09 = pd.DataFrame(flat_09)\n",
    "df5_09['year'] = 2009\n",
    "\n",
    "flat_10 = {}\n",
    "for name,arra in deg5_10.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_10[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_10.filled(np.nan).flatten()\n",
    "flat_10['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_10 = pd.DataFrame(flat_10)\n",
    "df5_10['year'] = 2010\n",
    "\n",
    "flat_11 = {}\n",
    "for name,arra in deg5_11.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_11[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_11.filled(np.nan).flatten()\n",
    "flat_11['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_11 = pd.DataFrame(flat_11)\n",
    "df5_11['year'] = 2011\n",
    "\n",
    "flat_12 = {}\n",
    "for name,arra in deg5_12.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_12[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_12.filled(np.nan).flatten()\n",
    "flat_12['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_12 = pd.DataFrame(flat_12)\n",
    "df5_12['year'] = 2012\n",
    "\n",
    "flat_13 = {}\n",
    "for name,arra in deg5_13.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_13[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_13.filled(np.nan).flatten()\n",
    "flat_13['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_13 = pd.DataFrame(flat_13)\n",
    "df5_13['year'] = 2013\n",
    "\n",
    "flat_14 = {}\n",
    "for name,arra in deg5_14.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_14[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_14.filled(np.nan).flatten()\n",
    "flat_14['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_14 = pd.DataFrame(flat_14)\n",
    "df5_14['year'] = 2014\n",
    "\n",
    "flat_15 = {}\n",
    "for name,arra in deg5_15.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_15[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_15.filled(np.nan).flatten()\n",
    "flat_15['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_15 = pd.DataFrame(flat_15)\n",
    "df5_15['year'] = 2015\n",
    "\n",
    "flat_16 = {}\n",
    "for name,arra in deg5_16.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_16[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_16.filled(np.nan).flatten()\n",
    "flat_16['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_16 = pd.DataFrame(flat_16)\n",
    "df5_16['year'] = 2016\n",
    "\n",
    "flat_17 = {}\n",
    "for name,arra in deg5_17.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_17[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_17.filled(np.nan).flatten()\n",
    "flat_17['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_17 = pd.DataFrame(flat_17)\n",
    "df5_17['year'] = 2017\n",
    "\n",
    "flat_18 = {}\n",
    "for name,arra in deg5_18.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_18[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio5_18.filled(np.nan).flatten()\n",
    "flat_18['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df5_18 = pd.DataFrame(flat_18)\n",
    "df5_18['year'] = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173607bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatteining arrays and turning into DataFrames with a 'year' column\n",
    "#Resolution: 10deg\n",
    "\n",
    "flat_00 = {}\n",
    "for name,arra in deg10_00.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_00[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_00.filled(np.nan).flatten()\n",
    "flat_00['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_00 = pd.DataFrame(flat_00)\n",
    "df10_00['year'] = 2000\n",
    "\n",
    "flat_01 = {}\n",
    "for name,arra in deg10_01.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_01[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_01.filled(np.nan).flatten()\n",
    "flat_01['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_01= pd.DataFrame(flat_01)\n",
    "df10_01['year'] = 2001\n",
    "\n",
    "flat_02 = {}\n",
    "for name,arra in deg10_02.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_02[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_02.filled(np.nan).flatten()\n",
    "flat_02['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_02 = pd.DataFrame(flat_02)\n",
    "df10_02['year'] = 2002\n",
    "\n",
    "flat_03 = {}\n",
    "for name,arra in deg10_03.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_03[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_03.filled(np.nan).flatten()\n",
    "flat_03['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_03 = pd.DataFrame(flat_03)\n",
    "df10_03['year'] = 2003\n",
    "\n",
    "flat_04 = {}\n",
    "for name,arra in deg10_04.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_04[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_04.filled(np.nan).flatten()\n",
    "flat_04['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_04 = pd.DataFrame(flat_04)\n",
    "df10_04['year'] = 2004\n",
    "\n",
    "flat_05 = {}\n",
    "for name,arra in deg10_05.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_05[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_05.filled(np.nan).flatten()\n",
    "flat_05['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_05 = pd.DataFrame(flat_05)\n",
    "df10_05['year'] = 2005\n",
    "\n",
    "flat_06 = {}\n",
    "for name,arra in deg10_06.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_06[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_06.filled(np.nan).flatten()\n",
    "flat_06['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_06 = pd.DataFrame(flat_06)\n",
    "df10_06['year'] = 2006\n",
    "\n",
    "flat_07 = {}\n",
    "for name,arra in deg10_07.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_07[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_07.filled(np.nan).flatten()\n",
    "flat_07['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_07 = pd.DataFrame(flat_07)\n",
    "df10_07['year'] = 2007\n",
    "\n",
    "flat_08 = {}\n",
    "for name,arra in deg10_08.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_08[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_08.filled(np.nan).flatten()\n",
    "flat_08['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_08 = pd.DataFrame(flat_08)\n",
    "df10_08['year'] = 2008\n",
    "\n",
    "flat_09 = {}\n",
    "for name,arra in deg10_09.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_09[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_09.filled(np.nan).flatten()\n",
    "flat_09['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_09 = pd.DataFrame(flat_09)\n",
    "df10_09['year'] = 2009\n",
    "\n",
    "flat_10 = {}\n",
    "for name,arra in deg10_10.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_10[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_10.filled(np.nan).flatten()\n",
    "flat_10['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_10 = pd.DataFrame(flat_10)\n",
    "df10_10['year'] = 2010\n",
    "\n",
    "flat_11 = {}\n",
    "for name,arra in deg10_11.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_11[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_11.filled(np.nan).flatten()\n",
    "flat_11['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_11 = pd.DataFrame(flat_11)\n",
    "df10_11['year'] = 2011\n",
    "\n",
    "flat_12 = {}\n",
    "for name,arra in deg10_12.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_12[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_12.filled(np.nan).flatten()\n",
    "flat_12['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_12 = pd.DataFrame(flat_12)\n",
    "df10_12['year'] = 2012\n",
    "\n",
    "flat_13 = {}\n",
    "for name,arra in deg10_13.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_13[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_13.filled(np.nan).flatten()\n",
    "flat_13['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_13 = pd.DataFrame(flat_13)\n",
    "df10_13['year'] = 2013\n",
    "\n",
    "flat_14 = {}\n",
    "for name,arra in deg10_14.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_14[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_14.filled(np.nan).flatten()\n",
    "flat_14['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_14 = pd.DataFrame(flat_14)\n",
    "df10_14['year'] = 2014\n",
    "\n",
    "flat_15 = {}\n",
    "for name,arra in deg10_15.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_15[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_15.filled(np.nan).flatten()\n",
    "flat_15['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_15 = pd.DataFrame(flat_15)\n",
    "df10_15['year'] = 2015\n",
    "\n",
    "flat_16 = {}\n",
    "for name,arra in deg10_16.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_16[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_16.filled(np.nan).flatten()\n",
    "flat_16['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_16 = pd.DataFrame(flat_16)\n",
    "df10_16['year'] = 2016\n",
    "\n",
    "flat_17 = {}\n",
    "for name,arra in deg10_17.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_17[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_17.filled(np.nan).flatten()\n",
    "flat_17['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_17 = pd.DataFrame(flat_17)\n",
    "df10_17['year'] = 2017\n",
    "\n",
    "flat_18 = {}\n",
    "for name,arra in deg10_18.items():\n",
    "#     print(name)\n",
    "    temp_arr = arra.filled(np.nan).flatten() # flattening array\n",
    "    flat_18[name] = temp_arr[~np.isnan(temp_arr)] #removing nans\n",
    "\n",
    "temp_bio = bio10_18.filled(np.nan).flatten()\n",
    "flat_18['bio_flux'] = temp_bio[~np.isnan(temp_bio)]\n",
    "df10_18 = pd.DataFrame(flat_18)\n",
    "df10_18['year'] = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee42182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1deg_yr = pd.concat([df_00,df_01,df_02,df_03,df_04,df_05,df_06,df_07,df_08,df_09,\n",
    "                         df_10,df_11,df_12,df_13,df_14,df_15,df_16,df_17,df_18])\n",
    "\n",
    "df_3deg_yr = pd.concat([df3_00,df3_01,df3_02,df3_03,df3_04,df3_05,df3_06,df3_07,df3_08,df3_09,\n",
    "                         df3_10,df3_11,df3_12,df3_13,df3_14,df3_15,df3_16,df3_17,df3_18])\n",
    "\n",
    "df_5deg_yr = pd.concat([df5_00,df5_01,df5_02,df5_03,df5_04,df5_05,df5_06,df5_07,df5_08,df5_09,\n",
    "                         df5_10,df5_11,df5_12,df5_13,df5_14,df5_15,df5_16,df5_17,df5_18])\n",
    "\n",
    "df_10deg_yr = pd.concat([df10_00,df10_01,df10_02,df10_03,df10_04,df10_05,df10_06,df10_07,df10_08,df10_09,\n",
    "                         df10_10,df10_11,df10_12,df10_13,df10_14,df10_15,df10_16,df10_17,df10_18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22280a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1deg_yr.to_csv('ERA_BIO_1d_yr.csv', index = False)\n",
    "df_3deg_yr.to_csv('ERA_BIO_3d_yr.csv', index = False)\n",
    "df_5deg_yr.to_csv('ERA_BIO_5d_yr.csv', index = False)\n",
    "df_10deg_yr.to_csv('ERA_BIO_10d_yr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b86854",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list =  ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "               'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7311481",
   "metadata": {},
   "source": [
    "These cells create a dataframe for each year and resolution which contain both 'year' and 'month' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffbb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2018_1 = deg1_18\n",
    "dict_2018_1['bio_flux'] = bio_18\n",
    "\n",
    "d_18_1 = {}\n",
    "D_18_1 = {}\n",
    "for key, value in dict_2018_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_18_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_18_1[key] = pd.concat(d_18_1, ignore_index = True)\n",
    "\n",
    "D_18_1 = pd.concat(D_18_1, axis = 1)\n",
    "D_18_1.columns = D_18_1.columns.droplevel()\n",
    "D_18_1 = D_18_1.T.drop_duplicates().T\n",
    "D_18_1['year'] = 2018\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2018_3 = deg3_18\n",
    "dict_2018_3['bio_flux'] = bio3_18\n",
    "\n",
    "d_18_3 = {}\n",
    "D_18_3 = {}\n",
    "for key, value in dict_2018_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_18_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_18_3[key] = pd.concat(d_18_3, ignore_index = True)\n",
    "\n",
    "D_18_3 = pd.concat(D_18_3, axis = 1)\n",
    "D_18_3.columns = D_18_3.columns.droplevel()\n",
    "D_18_3 = D_18_3.T.drop_duplicates().T\n",
    "D_18_3['year'] = 2018\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2018_5 = deg5_18\n",
    "dict_2018_5['bio_flux'] = bio5_18\n",
    "\n",
    "d_18_5 = {}\n",
    "D_18_5 = {}\n",
    "for key, value in dict_2018_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_18_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_18_5[key] = pd.concat(d_18_5, ignore_index = True)\n",
    "\n",
    "D_18_5 = pd.concat(D_18_5, axis = 1)\n",
    "D_18_5.columns = D_18_5.columns.droplevel()\n",
    "D_18_5 = D_18_5.T.drop_duplicates().T\n",
    "D_18_5['year'] = 2018\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2018_10 = deg10_18\n",
    "dict_2018_10['bio_flux'] = bio10_18\n",
    "\n",
    "d_18_10 = {}\n",
    "D_18_10 = {}\n",
    "for key, value in dict_2018_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_18_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_18_10[key] = pd.concat(d_18_10, ignore_index = True)\n",
    "\n",
    "D_18_10 = pd.concat(D_18_10, axis = 1)\n",
    "D_18_10.columns = D_18_10.columns.droplevel()\n",
    "D_18_10 = D_18_10.T.drop_duplicates().T\n",
    "D_18_10['year'] = 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2017_1 = deg1_17\n",
    "dict_2017_1['bio_flux'] = bio_17\n",
    "\n",
    "d_17_1 = {}\n",
    "D_17_1 = {}\n",
    "for key, value in dict_2017_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_17_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_17_1[key] = pd.concat(d_17_1, ignore_index = True)\n",
    "\n",
    "D_17_1 = pd.concat(D_17_1, axis = 1)\n",
    "D_17_1.columns = D_17_1.columns.droplevel()\n",
    "D_17_1 = D_17_1.T.drop_duplicates().T\n",
    "D_17_1['year'] = 2017\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2017_3 = deg3_17\n",
    "dict_2017_3['bio_flux'] = bio3_17\n",
    "\n",
    "d_17_3 = {}\n",
    "D_17_3 = {}\n",
    "for key, value in dict_2017_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_17_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_17_3[key] = pd.concat(d_17_3, ignore_index = True)\n",
    "\n",
    "D_17_3 = pd.concat(D_17_3, axis = 1)\n",
    "D_17_3.columns = D_17_3.columns.droplevel()\n",
    "D_17_3 = D_17_3.T.drop_duplicates().T\n",
    "D_17_3['year'] = 2017\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2017_5 = deg5_17\n",
    "dict_2017_5['bio_flux'] = bio5_17\n",
    "\n",
    "d_17_5 = {}\n",
    "D_17_5 = {}\n",
    "for key, value in dict_2017_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_17_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_17_5[key] = pd.concat(d_17_5, ignore_index = True)\n",
    "\n",
    "D_17_5 = pd.concat(D_17_5, axis = 1)\n",
    "D_17_5.columns = D_17_5.columns.droplevel()\n",
    "D_17_5 = D_17_5.T.drop_duplicates().T\n",
    "D_17_5['year'] = 2017\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2017_10 = deg10_17\n",
    "dict_2017_10['bio_flux'] = bio10_17\n",
    "\n",
    "d_17_10 = {}\n",
    "D_17_10 = {}\n",
    "for key, value in dict_2017_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_17_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_17_10[key] = pd.concat(d_17_10, ignore_index = True)\n",
    "\n",
    "D_17_10 = pd.concat(D_17_10, axis = 1)\n",
    "D_17_10.columns = D_17_10.columns.droplevel()\n",
    "D_17_10 = D_17_10.T.drop_duplicates().T\n",
    "D_17_10['year'] = 2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2016_1 = deg1_16\n",
    "dict_2016_1['bio_flux'] = bio_16\n",
    "\n",
    "d_16_1 = {}\n",
    "D_16_1 = {}\n",
    "for key, value in dict_2016_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_16_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_16_1[key] = pd.concat(d_16_1, ignore_index = True)\n",
    "\n",
    "D_16_1 = pd.concat(D_16_1, axis = 1)\n",
    "D_16_1.columns = D_16_1.columns.droplevel()\n",
    "D_16_1 = D_16_1.T.drop_duplicates().T\n",
    "D_16_1['year'] = 2016\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2016_3 = deg3_16\n",
    "dict_2016_3['bio_flux'] = bio3_16\n",
    "\n",
    "d_16_3 = {}\n",
    "D_16_3 = {}\n",
    "for key, value in dict_2016_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_16_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_16_3[key] = pd.concat(d_16_3, ignore_index = True)\n",
    "\n",
    "D_16_3 = pd.concat(D_16_3, axis = 1)\n",
    "D_16_3.columns = D_16_3.columns.droplevel()\n",
    "D_16_3 = D_16_3.T.drop_duplicates().T\n",
    "D_16_3['year'] = 2016\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2016_5 = deg5_16\n",
    "dict_2016_5['bio_flux'] = bio5_16\n",
    "\n",
    "d_16_5 = {}\n",
    "D_16_5 = {}\n",
    "for key, value in dict_2016_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_16_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_16_5[key] = pd.concat(d_16_5, ignore_index = True)\n",
    "\n",
    "D_16_5 = pd.concat(D_16_5, axis = 1)\n",
    "D_16_5.columns = D_16_5.columns.droplevel()\n",
    "D_16_5 = D_16_5.T.drop_duplicates().T\n",
    "D_16_5['year'] = 2016\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2016_10 = deg10_16\n",
    "dict_2016_10['bio_flux'] = bio10_16\n",
    "\n",
    "d_16_10 = {}\n",
    "D_16_10 = {}\n",
    "for key, value in dict_2016_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_16_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_16_10[key] = pd.concat(d_16_10, ignore_index = True)\n",
    "\n",
    "D_16_10 = pd.concat(D_16_10, axis = 1)\n",
    "D_16_10.columns = D_16_10.columns.droplevel()\n",
    "D_16_10 = D_16_10.T.drop_duplicates().T\n",
    "D_16_10['year'] = 2016\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ad6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2015_1 = deg1_15\n",
    "dict_2015_1['bio_flux'] = bio_15\n",
    "\n",
    "d_15_1 = {}\n",
    "D_15_1 = {}\n",
    "for key, value in dict_2015_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_15_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_15_1[key] = pd.concat(d_15_1, ignore_index = True)\n",
    "\n",
    "D_15_1 = pd.concat(D_15_1, axis = 1)\n",
    "D_15_1.columns = D_15_1.columns.droplevel()\n",
    "D_15_1 = D_15_1.T.drop_duplicates().T\n",
    "D_15_1['year'] = 2015\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2015_3 = deg3_15\n",
    "dict_2015_3['bio_flux'] = bio3_15\n",
    "\n",
    "d_15_3 = {}\n",
    "D_15_3 = {}\n",
    "for key, value in dict_2015_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_15_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_15_3[key] = pd.concat(d_15_3, ignore_index = True)\n",
    "\n",
    "D_15_3 = pd.concat(D_15_3, axis = 1)\n",
    "D_15_3.columns = D_15_3.columns.droplevel()\n",
    "D_15_3 = D_15_3.T.drop_duplicates().T\n",
    "D_15_3['year'] = 2015\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2015_5 = deg5_15\n",
    "dict_2015_5['bio_flux'] = bio5_15\n",
    "\n",
    "d_15_5 = {}\n",
    "D_15_5 = {}\n",
    "for key, value in dict_2015_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_15_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_15_5[key] = pd.concat(d_15_5, ignore_index = True)\n",
    "\n",
    "D_15_5 = pd.concat(D_15_5, axis = 1)\n",
    "D_15_5.columns = D_15_5.columns.droplevel()\n",
    "D_15_5 = D_15_5.T.drop_duplicates().T\n",
    "D_15_5['year'] = 2015\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2015_10 = deg10_15\n",
    "dict_2015_10['bio_flux'] = bio10_15\n",
    "\n",
    "d_15_10 = {}\n",
    "D_15_10 = {}\n",
    "for key, value in dict_2015_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_15_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_15_10[key] = pd.concat(d_15_10, ignore_index = True)\n",
    "\n",
    "D_15_10 = pd.concat(D_15_10, axis = 1)\n",
    "D_15_10.columns = D_15_10.columns.droplevel()\n",
    "D_15_10 = D_15_10.T.drop_duplicates().T\n",
    "D_15_10['year'] = 2015\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2014_1 = deg1_14\n",
    "dict_2014_1['bio_flux'] = bio_14\n",
    "\n",
    "d_14_1 = {}\n",
    "D_14_1 = {}\n",
    "for key, value in dict_2014_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_14_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_14_1[key] = pd.concat(d_14_1, ignore_index = True)\n",
    "\n",
    "D_14_1 = pd.concat(D_14_1, axis = 1)\n",
    "D_14_1.columns = D_14_1.columns.droplevel()\n",
    "D_14_1 = D_14_1.T.drop_duplicates().T\n",
    "D_14_1['year'] = 2014\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2014_3 = deg3_14\n",
    "dict_2014_3['bio_flux'] = bio3_14\n",
    "\n",
    "d_14_3 = {}\n",
    "D_14_3 = {}\n",
    "for key, value in dict_2014_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_14_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_14_3[key] = pd.concat(d_14_3, ignore_index = True)\n",
    "\n",
    "D_14_3 = pd.concat(D_14_3, axis = 1)\n",
    "D_14_3.columns = D_14_3.columns.droplevel()\n",
    "D_14_3 = D_14_3.T.drop_duplicates().T\n",
    "D_14_3['year'] = 2014\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2014_5 = deg5_14\n",
    "dict_2014_5['bio_flux'] = bio5_14\n",
    "\n",
    "d_14_5 = {}\n",
    "D_14_5 = {}\n",
    "for key, value in dict_2014_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_14_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_14_5[key] = pd.concat(d_14_5, ignore_index = True)\n",
    "\n",
    "D_14_5 = pd.concat(D_14_5, axis = 1)\n",
    "D_14_5.columns = D_14_5.columns.droplevel()\n",
    "D_14_5 = D_14_5.T.drop_duplicates().T\n",
    "D_14_5['year'] = 2014\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2014_10 = deg10_14\n",
    "dict_2014_10['bio_flux'] = bio10_14\n",
    "\n",
    "d_14_10 = {}\n",
    "D_14_10 = {}\n",
    "for key, value in dict_2014_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_14_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_14_10[key] = pd.concat(d_14_10, ignore_index = True)\n",
    "\n",
    "D_14_10 = pd.concat(D_14_10, axis = 1)\n",
    "D_14_10.columns = D_14_10.columns.droplevel()\n",
    "D_14_10 = D_14_10.T.drop_duplicates().T\n",
    "D_14_10['year'] = 2014\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c267abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2013_1 = deg1_13\n",
    "dict_2013_1['bio_flux'] = bio_13\n",
    "\n",
    "d_13_1 = {}\n",
    "D_13_1 = {}\n",
    "for key, value in dict_2013_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_13_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_13_1[key] = pd.concat(d_13_1, ignore_index = True)\n",
    "\n",
    "D_13_1 = pd.concat(D_13_1, axis = 1)\n",
    "D_13_1.columns = D_13_1.columns.droplevel()\n",
    "D_13_1 = D_13_1.T.drop_duplicates().T\n",
    "D_13_1['year'] = 2013\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2013_3 = deg3_13\n",
    "dict_2013_3['bio_flux'] = bio3_13\n",
    "\n",
    "d_13_3 = {}\n",
    "D_13_3 = {}\n",
    "for key, value in dict_2013_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_13_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_13_3[key] = pd.concat(d_13_3, ignore_index = True)\n",
    "\n",
    "D_13_3 = pd.concat(D_13_3, axis = 1)\n",
    "D_13_3.columns = D_13_3.columns.droplevel()\n",
    "D_13_3 = D_13_3.T.drop_duplicates().T\n",
    "D_13_3['year'] = 2013\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2013_5 = deg5_13\n",
    "dict_2013_5['bio_flux'] = bio5_13\n",
    "\n",
    "d_13_5 = {}\n",
    "D_13_5 = {}\n",
    "for key, value in dict_2013_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_13_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_13_5[key] = pd.concat(d_13_5, ignore_index = True)\n",
    "\n",
    "D_13_5 = pd.concat(D_13_5, axis = 1)\n",
    "D_13_5.columns = D_13_5.columns.droplevel()\n",
    "D_13_5 = D_13_5.T.drop_duplicates().T\n",
    "D_13_5['year'] = 2013\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2013_10 = deg10_13\n",
    "dict_2013_10['bio_flux'] = bio10_13\n",
    "\n",
    "d_13_10 = {}\n",
    "D_13_10 = {}\n",
    "for key, value in dict_2013_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_13_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_13_10[key] = pd.concat(d_13_10, ignore_index = True)\n",
    "\n",
    "D_13_10 = pd.concat(D_13_10, axis = 1)\n",
    "D_13_10.columns = D_13_10.columns.droplevel()\n",
    "D_13_10 = D_13_10.T.drop_duplicates().T\n",
    "D_13_10['year'] = 2013\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2012_1 = deg1_12\n",
    "dict_2012_1['bio_flux'] = bio_12\n",
    "\n",
    "d_12_1 = {}\n",
    "D_12_1 = {}\n",
    "for key, value in dict_2012_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_12_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_12_1[key] = pd.concat(d_12_1, ignore_index = True)\n",
    "\n",
    "D_12_1 = pd.concat(D_12_1, axis = 1)\n",
    "D_12_1.columns = D_12_1.columns.droplevel()\n",
    "D_12_1 = D_12_1.T.drop_duplicates().T\n",
    "D_12_1['year'] = 2012\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2012_3 = deg3_12\n",
    "dict_2012_3['bio_flux'] = bio3_12\n",
    "\n",
    "d_12_3 = {}\n",
    "D_12_3 = {}\n",
    "for key, value in dict_2012_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_12_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_12_3[key] = pd.concat(d_12_3, ignore_index = True)\n",
    "\n",
    "D_12_3 = pd.concat(D_12_3, axis = 1)\n",
    "D_12_3.columns = D_12_3.columns.droplevel()\n",
    "D_12_3 = D_12_3.T.drop_duplicates().T\n",
    "D_12_3['year'] = 2012\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2012_5 = deg5_12\n",
    "dict_2012_5['bio_flux'] = bio5_12\n",
    "\n",
    "d_12_5 = {}\n",
    "D_12_5 = {}\n",
    "for key, value in dict_2012_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_12_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_12_5[key] = pd.concat(d_12_5, ignore_index = True)\n",
    "\n",
    "D_12_5 = pd.concat(D_12_5, axis = 1)\n",
    "D_12_5.columns = D_12_5.columns.droplevel()\n",
    "D_12_5 = D_12_5.T.drop_duplicates().T\n",
    "D_12_5['year'] = 2012\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2012_10 = deg10_12\n",
    "dict_2012_10['bio_flux'] = bio10_12\n",
    "\n",
    "d_12_10 = {}\n",
    "D_12_10 = {}\n",
    "for key, value in dict_2012_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_12_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_12_10[key] = pd.concat(d_12_10, ignore_index = True)\n",
    "\n",
    "D_12_10 = pd.concat(D_12_10, axis = 1)\n",
    "D_12_10.columns = D_12_10.columns.droplevel()\n",
    "D_12_10 = D_12_10.T.drop_duplicates().T\n",
    "D_12_10['year'] = 2012\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2011_1 = deg1_11\n",
    "dict_2011_1['bio_flux'] = bio_11\n",
    "\n",
    "d_11_1 = {}\n",
    "D_11_1 = {}\n",
    "for key, value in dict_2011_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_11_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_11_1[key] = pd.concat(d_11_1, ignore_index = True)\n",
    "\n",
    "D_11_1 = pd.concat(D_11_1, axis = 1)\n",
    "D_11_1.columns = D_11_1.columns.droplevel()\n",
    "D_11_1 = D_11_1.T.drop_duplicates().T\n",
    "D_11_1['year'] = 2011\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2011_3 = deg3_11\n",
    "dict_2011_3['bio_flux'] = bio3_11\n",
    "\n",
    "d_11_3 = {}\n",
    "D_11_3 = {}\n",
    "for key, value in dict_2011_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_11_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_11_3[key] = pd.concat(d_11_3, ignore_index = True)\n",
    "\n",
    "D_11_3 = pd.concat(D_11_3, axis = 1)\n",
    "D_11_3.columns = D_11_3.columns.droplevel()\n",
    "D_11_3 = D_11_3.T.drop_duplicates().T\n",
    "D_11_3['year'] = 2011\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2011_5 = deg5_11\n",
    "dict_2011_5['bio_flux'] = bio5_11\n",
    "\n",
    "d_11_5 = {}\n",
    "D_11_5 = {}\n",
    "for key, value in dict_2011_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_11_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_11_5[key] = pd.concat(d_11_5, ignore_index = True)\n",
    "\n",
    "D_11_5 = pd.concat(D_11_5, axis = 1)\n",
    "D_11_5.columns = D_11_5.columns.droplevel()\n",
    "D_11_5 = D_11_5.T.drop_duplicates().T\n",
    "D_11_5['year'] = 2011\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2011_10 = deg10_11\n",
    "dict_2011_10['bio_flux'] = bio10_11\n",
    "\n",
    "d_11_10 = {}\n",
    "D_11_10 = {}\n",
    "for key, value in dict_2011_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_11_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_11_10[key] = pd.concat(d_11_10, ignore_index = True)\n",
    "\n",
    "D_11_10 = pd.concat(D_11_10, axis = 1)\n",
    "D_11_10.columns = D_11_10.columns.droplevel()\n",
    "D_11_10 = D_11_10.T.drop_duplicates().T\n",
    "D_11_10['year'] = 2011\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2010_1 = deg1_10\n",
    "dict_2010_1['bio_flux'] = bio_10\n",
    "\n",
    "d_10_1 = {}\n",
    "D_10_1 = {}\n",
    "for key, value in dict_2010_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_10_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_10_1[key] = pd.concat(d_10_1, ignore_index = True)\n",
    "\n",
    "D_10_1 = pd.concat(D_10_1, axis = 1)\n",
    "D_10_1.columns = D_10_1.columns.droplevel()\n",
    "D_10_1 = D_10_1.T.drop_duplicates().T\n",
    "D_10_1['year'] = 2010\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2010_3 = deg3_10\n",
    "dict_2010_3['bio_flux'] = bio3_10\n",
    "\n",
    "d_10_3 = {}\n",
    "D_10_3 = {}\n",
    "for key, value in dict_2010_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_10_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_10_3[key] = pd.concat(d_10_3, ignore_index = True)\n",
    "\n",
    "D_10_3 = pd.concat(D_10_3, axis = 1)\n",
    "D_10_3.columns = D_10_3.columns.droplevel()\n",
    "D_10_3 = D_10_3.T.drop_duplicates().T\n",
    "D_10_3['year'] = 2010\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2010_5 = deg5_10\n",
    "dict_2010_5['bio_flux'] = bio5_10\n",
    "\n",
    "d_10_5 = {}\n",
    "D_10_5 = {}\n",
    "for key, value in dict_2010_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_10_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_10_5[key] = pd.concat(d_10_5, ignore_index = True)\n",
    "\n",
    "D_10_5 = pd.concat(D_10_5, axis = 1)\n",
    "D_10_5.columns = D_10_5.columns.droplevel()\n",
    "D_10_5 = D_10_5.T.drop_duplicates().T\n",
    "D_10_5['year'] = 2010\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2010_10 = deg10_10\n",
    "dict_2010_10['bio_flux'] = bio10_10\n",
    "\n",
    "d_10_10 = {}\n",
    "D_10_10 = {}\n",
    "for key, value in dict_2010_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_10_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_10_10[key] = pd.concat(d_10_10, ignore_index = True)\n",
    "\n",
    "D_10_10 = pd.concat(D_10_10, axis = 1)\n",
    "D_10_10.columns = D_10_10.columns.droplevel()\n",
    "D_10_10 = D_10_10.T.drop_duplicates().T\n",
    "D_10_10['year'] = 2010\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43311a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2009_1 = deg1_09\n",
    "dict_2009_1['bio_flux'] = bio_09\n",
    "\n",
    "d_09_1 = {}\n",
    "D_09_1 = {}\n",
    "for key, value in dict_2009_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_09_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_09_1[key] = pd.concat(d_09_1, ignore_index = True)\n",
    "\n",
    "D_09_1 = pd.concat(D_09_1, axis = 1)\n",
    "D_09_1.columns = D_09_1.columns.droplevel()\n",
    "D_09_1 = D_09_1.T.drop_duplicates().T\n",
    "D_09_1['year'] = 2009\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2009_3 = deg3_09\n",
    "dict_2009_3['bio_flux'] = bio3_09\n",
    "\n",
    "d_09_3 = {}\n",
    "D_09_3 = {}\n",
    "for key, value in dict_2009_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_09_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_09_3[key] = pd.concat(d_09_3, ignore_index = True)\n",
    "\n",
    "D_09_3 = pd.concat(D_09_3, axis = 1)\n",
    "D_09_3.columns = D_09_3.columns.droplevel()\n",
    "D_09_3 = D_09_3.T.drop_duplicates().T\n",
    "D_09_3['year'] = 2009\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2009_5 = deg5_09\n",
    "dict_2009_5['bio_flux'] = bio5_09\n",
    "\n",
    "d_09_5 = {}\n",
    "D_09_5 = {}\n",
    "for key, value in dict_2009_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_09_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_09_5[key] = pd.concat(d_09_5, ignore_index = True)\n",
    "\n",
    "D_09_5 = pd.concat(D_09_5, axis = 1)\n",
    "D_09_5.columns = D_09_5.columns.droplevel()\n",
    "D_09_5 = D_09_5.T.drop_duplicates().T\n",
    "D_09_5['year'] = 2009\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2009_10 = deg10_09\n",
    "dict_2009_10['bio_flux'] = bio10_09\n",
    "\n",
    "d_09_10 = {}\n",
    "D_09_10 = {}\n",
    "for key, value in dict_2009_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_09_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_09_10[key] = pd.concat(d_09_10, ignore_index = True)\n",
    "\n",
    "D_09_10 = pd.concat(D_09_10, axis = 1)\n",
    "D_09_10.columns = D_09_10.columns.droplevel()\n",
    "D_09_10 = D_09_10.T.drop_duplicates().T\n",
    "D_09_10['year'] = 2009\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2008_1 = deg1_08\n",
    "dict_2008_1['bio_flux'] = bio_08\n",
    "\n",
    "d_08_1 = {}\n",
    "D_08_1 = {}\n",
    "for key, value in dict_2008_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_08_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_08_1[key] = pd.concat(d_08_1, ignore_index = True)\n",
    "\n",
    "D_08_1 = pd.concat(D_08_1, axis = 1)\n",
    "D_08_1.columns = D_08_1.columns.droplevel()\n",
    "D_08_1 = D_08_1.T.drop_duplicates().T\n",
    "D_08_1['year'] = 2008\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2008_3 = deg3_08\n",
    "dict_2008_3['bio_flux'] = bio3_08\n",
    "\n",
    "d_08_3 = {}\n",
    "D_08_3 = {}\n",
    "for key, value in dict_2008_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_08_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_08_3[key] = pd.concat(d_08_3, ignore_index = True)\n",
    "\n",
    "D_08_3 = pd.concat(D_08_3, axis = 1)\n",
    "D_08_3.columns = D_08_3.columns.droplevel()\n",
    "D_08_3 = D_08_3.T.drop_duplicates().T\n",
    "D_08_3['year'] = 2008\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2008_5 = deg5_08\n",
    "dict_2008_5['bio_flux'] = bio5_08\n",
    "\n",
    "d_08_5 = {}\n",
    "D_08_5 = {}\n",
    "for key, value in dict_2008_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_08_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_08_5[key] = pd.concat(d_08_5, ignore_index = True)\n",
    "\n",
    "D_08_5 = pd.concat(D_08_5, axis = 1)\n",
    "D_08_5.columns = D_08_5.columns.droplevel()\n",
    "D_08_5 = D_08_5.T.drop_duplicates().T\n",
    "D_08_5['year'] = 2008\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2008_10 = deg10_08\n",
    "dict_2008_10['bio_flux'] = bio10_08\n",
    "\n",
    "d_08_10 = {}\n",
    "D_08_10 = {}\n",
    "for key, value in dict_2008_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_08_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_08_10[key] = pd.concat(d_08_10, ignore_index = True)\n",
    "\n",
    "D_08_10 = pd.concat(D_08_10, axis = 1)\n",
    "D_08_10.columns = D_08_10.columns.droplevel()\n",
    "D_08_10 = D_08_10.T.drop_duplicates().T\n",
    "D_08_10['year'] = 2008\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88af7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2007_1 = deg1_07\n",
    "dict_2007_1['bio_flux'] = bio_07\n",
    "\n",
    "d_07_1 = {}\n",
    "D_07_1 = {}\n",
    "for key, value in dict_2007_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_07_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_07_1[key] = pd.concat(d_07_1, ignore_index = True)\n",
    "\n",
    "D_07_1 = pd.concat(D_07_1, axis = 1)\n",
    "D_07_1.columns = D_07_1.columns.droplevel()\n",
    "D_07_1 = D_07_1.T.drop_duplicates().T\n",
    "D_07_1['year'] = 2007\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2007_3 = deg3_07\n",
    "dict_2007_3['bio_flux'] = bio3_07\n",
    "\n",
    "d_07_3 = {}\n",
    "D_07_3 = {}\n",
    "for key, value in dict_2007_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_07_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_07_3[key] = pd.concat(d_07_3, ignore_index = True)\n",
    "\n",
    "D_07_3 = pd.concat(D_07_3, axis = 1)\n",
    "D_07_3.columns = D_07_3.columns.droplevel()\n",
    "D_07_3 = D_07_3.T.drop_duplicates().T\n",
    "D_07_3['year'] = 2007\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2007_5 = deg5_07\n",
    "dict_2007_5['bio_flux'] = bio5_07\n",
    "\n",
    "d_07_5 = {}\n",
    "D_07_5 = {}\n",
    "for key, value in dict_2007_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_07_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_07_5[key] = pd.concat(d_07_5, ignore_index = True)\n",
    "\n",
    "D_07_5 = pd.concat(D_07_5, axis = 1)\n",
    "D_07_5.columns = D_07_5.columns.droplevel()\n",
    "D_07_5 = D_07_5.T.drop_duplicates().T\n",
    "D_07_5['year'] = 2007\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2007_10 = deg10_07\n",
    "dict_2007_10['bio_flux'] = bio10_07\n",
    "\n",
    "d_07_10 = {}\n",
    "D_07_10 = {}\n",
    "for key, value in dict_2007_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_07_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_07_10[key] = pd.concat(d_07_10, ignore_index = True)\n",
    "\n",
    "D_07_10 = pd.concat(D_07_10, axis = 1)\n",
    "D_07_10.columns = D_07_10.columns.droplevel()\n",
    "D_07_10 = D_07_10.T.drop_duplicates().T\n",
    "D_07_10['year'] = 2007\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4885b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2006_1 = deg1_06\n",
    "dict_2006_1['bio_flux'] = bio_06\n",
    "\n",
    "d_06_1 = {}\n",
    "D_06_1 = {}\n",
    "for key, value in dict_2006_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_06_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_06_1[key] = pd.concat(d_06_1, ignore_index = True)\n",
    "\n",
    "D_06_1 = pd.concat(D_06_1, axis = 1)\n",
    "D_06_1.columns = D_06_1.columns.droplevel()\n",
    "D_06_1 = D_06_1.T.drop_duplicates().T\n",
    "D_06_1['year'] = 2006\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2006_3 = deg3_06\n",
    "dict_2006_3['bio_flux'] = bio3_06\n",
    "\n",
    "d_06_3 = {}\n",
    "D_06_3 = {}\n",
    "for key, value in dict_2006_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_06_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_06_3[key] = pd.concat(d_06_3, ignore_index = True)\n",
    "\n",
    "D_06_3 = pd.concat(D_06_3, axis = 1)\n",
    "D_06_3.columns = D_06_3.columns.droplevel()\n",
    "D_06_3 = D_06_3.T.drop_duplicates().T\n",
    "D_06_3['year'] = 2006\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2006_5 = deg5_06\n",
    "dict_2006_5['bio_flux'] = bio5_06\n",
    "\n",
    "d_06_5 = {}\n",
    "D_06_5 = {}\n",
    "for key, value in dict_2006_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_06_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_06_5[key] = pd.concat(d_06_5, ignore_index = True)\n",
    "\n",
    "D_06_5 = pd.concat(D_06_5, axis = 1)\n",
    "D_06_5.columns = D_06_5.columns.droplevel()\n",
    "D_06_5 = D_06_5.T.drop_duplicates().T\n",
    "D_06_5['year'] = 2006\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2006_10 = deg10_06\n",
    "dict_2006_10['bio_flux'] = bio10_06\n",
    "\n",
    "d_06_10 = {}\n",
    "D_06_10 = {}\n",
    "for key, value in dict_2006_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_06_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_06_10[key] = pd.concat(d_06_10, ignore_index = True)\n",
    "\n",
    "D_06_10 = pd.concat(D_06_10, axis = 1)\n",
    "D_06_10.columns = D_06_10.columns.droplevel()\n",
    "D_06_10 = D_06_10.T.drop_duplicates().T\n",
    "D_06_10['year'] = 2006\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1326023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2005_1 = deg1_05\n",
    "dict_2005_1['bio_flux'] = bio_05\n",
    "\n",
    "d_05_1 = {}\n",
    "D_05_1 = {}\n",
    "for key, value in dict_2005_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_05_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_05_1[key] = pd.concat(d_05_1, ignore_index = True)\n",
    "\n",
    "D_05_1 = pd.concat(D_05_1, axis = 1)\n",
    "D_05_1.columns = D_05_1.columns.droplevel()\n",
    "D_05_1 = D_05_1.T.drop_duplicates().T\n",
    "D_05_1['year'] = 2005\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2005_3 = deg3_05\n",
    "dict_2005_3['bio_flux'] = bio3_05\n",
    "\n",
    "d_05_3 = {}\n",
    "D_05_3 = {}\n",
    "for key, value in dict_2005_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_05_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_05_3[key] = pd.concat(d_05_3, ignore_index = True)\n",
    "\n",
    "D_05_3 = pd.concat(D_05_3, axis = 1)\n",
    "D_05_3.columns = D_05_3.columns.droplevel()\n",
    "D_05_3 = D_05_3.T.drop_duplicates().T\n",
    "D_05_3['year'] = 2005\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2005_5 = deg5_05\n",
    "dict_2005_5['bio_flux'] = bio5_05\n",
    "\n",
    "d_05_5 = {}\n",
    "D_05_5 = {}\n",
    "for key, value in dict_2005_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_05_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_05_5[key] = pd.concat(d_05_5, ignore_index = True)\n",
    "\n",
    "D_05_5 = pd.concat(D_05_5, axis = 1)\n",
    "D_05_5.columns = D_05_5.columns.droplevel()\n",
    "D_05_5 = D_05_5.T.drop_duplicates().T\n",
    "D_05_5['year'] = 2005\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2005_10 = deg10_05\n",
    "dict_2005_10['bio_flux'] = bio10_05\n",
    "\n",
    "d_05_10 = {}\n",
    "D_05_10 = {}\n",
    "for key, value in dict_2005_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_05_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_05_10[key] = pd.concat(d_05_10, ignore_index = True)\n",
    "\n",
    "D_05_10 = pd.concat(D_05_10, axis = 1)\n",
    "D_05_10.columns = D_05_10.columns.droplevel()\n",
    "D_05_10 = D_05_10.T.drop_duplicates().T\n",
    "D_05_10['year'] = 2005\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2004_1 = deg1_04\n",
    "dict_2004_1['bio_flux'] = bio_04\n",
    "\n",
    "d_04_1 = {}\n",
    "D_04_1 = {}\n",
    "for key, value in dict_2004_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_04_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_04_1[key] = pd.concat(d_04_1, ignore_index = True)\n",
    "\n",
    "D_04_1 = pd.concat(D_04_1, axis = 1)\n",
    "D_04_1.columns = D_04_1.columns.droplevel()\n",
    "D_04_1 = D_04_1.T.drop_duplicates().T\n",
    "D_04_1['year'] = 2004\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2004_3 = deg3_04\n",
    "dict_2004_3['bio_flux'] = bio3_04\n",
    "\n",
    "d_04_3 = {}\n",
    "D_04_3 = {}\n",
    "for key, value in dict_2004_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_04_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_04_3[key] = pd.concat(d_04_3, ignore_index = True)\n",
    "\n",
    "D_04_3 = pd.concat(D_04_3, axis = 1)\n",
    "D_04_3.columns = D_04_3.columns.droplevel()\n",
    "D_04_3 = D_04_3.T.drop_duplicates().T\n",
    "D_04_3['year'] = 2004\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2004_5 = deg5_04\n",
    "dict_2004_5['bio_flux'] = bio5_04\n",
    "\n",
    "d_04_5 = {}\n",
    "D_04_5 = {}\n",
    "for key, value in dict_2004_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_04_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_04_5[key] = pd.concat(d_04_5, ignore_index = True)\n",
    "\n",
    "D_04_5 = pd.concat(D_04_5, axis = 1)\n",
    "D_04_5.columns = D_04_5.columns.droplevel()\n",
    "D_04_5 = D_04_5.T.drop_duplicates().T\n",
    "D_04_5['year'] = 2004\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2004_10 = deg10_04\n",
    "dict_2004_10['bio_flux'] = bio10_04\n",
    "\n",
    "d_04_10 = {}\n",
    "D_04_10 = {}\n",
    "for key, value in dict_2004_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_04_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_04_10[key] = pd.concat(d_04_10, ignore_index = True)\n",
    "\n",
    "D_04_10 = pd.concat(D_04_10, axis = 1)\n",
    "D_04_10.columns = D_04_10.columns.droplevel()\n",
    "D_04_10 = D_04_10.T.drop_duplicates().T\n",
    "D_04_10['year'] = 2004\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2003_1 = deg1_03\n",
    "dict_2003_1['bio_flux'] = bio_03\n",
    "\n",
    "d_03_1 = {}\n",
    "D_03_1 = {}\n",
    "for key, value in dict_2003_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_03_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_03_1[key] = pd.concat(d_03_1, ignore_index = True)\n",
    "\n",
    "D_03_1 = pd.concat(D_03_1, axis = 1)\n",
    "D_03_1.columns = D_03_1.columns.droplevel()\n",
    "D_03_1 = D_03_1.T.drop_duplicates().T\n",
    "D_03_1['year'] = 2003\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2003_3 = deg3_03\n",
    "dict_2003_3['bio_flux'] = bio3_03\n",
    "\n",
    "d_03_3 = {}\n",
    "D_03_3 = {}\n",
    "for key, value in dict_2003_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_03_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_03_3[key] = pd.concat(d_03_3, ignore_index = True)\n",
    "\n",
    "D_03_3 = pd.concat(D_03_3, axis = 1)\n",
    "D_03_3.columns = D_03_3.columns.droplevel()\n",
    "D_03_3 = D_03_3.T.drop_duplicates().T\n",
    "D_03_3['year'] = 2003\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2003_5 = deg5_03\n",
    "dict_2003_5['bio_flux'] = bio5_03\n",
    "\n",
    "d_03_5 = {}\n",
    "D_03_5 = {}\n",
    "for key, value in dict_2003_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_03_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_03_5[key] = pd.concat(d_03_5, ignore_index = True)\n",
    "\n",
    "D_03_5 = pd.concat(D_03_5, axis = 1)\n",
    "D_03_5.columns = D_03_5.columns.droplevel()\n",
    "D_03_5 = D_03_5.T.drop_duplicates().T\n",
    "D_03_5['year'] = 2003\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2003_10 = deg10_03\n",
    "dict_2003_10['bio_flux'] = bio10_03\n",
    "\n",
    "d_03_10 = {}\n",
    "D_03_10 = {}\n",
    "for key, value in dict_2003_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_03_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_03_10[key] = pd.concat(d_03_10, ignore_index = True)\n",
    "\n",
    "D_03_10 = pd.concat(D_03_10, axis = 1)\n",
    "D_03_10.columns = D_03_10.columns.droplevel()\n",
    "D_03_10 = D_03_10.T.drop_duplicates().T\n",
    "D_03_10['year'] = 2003\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a27d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2002_1 = deg1_02\n",
    "dict_2002_1['bio_flux'] = bio_02\n",
    "\n",
    "d_02_1 = {}\n",
    "D_02_1 = {}\n",
    "for key, value in dict_2002_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_02_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_02_1[key] = pd.concat(d_02_1, ignore_index = True)\n",
    "\n",
    "D_02_1 = pd.concat(D_02_1, axis = 1)\n",
    "D_02_1.columns = D_02_1.columns.droplevel()\n",
    "D_02_1 = D_02_1.T.drop_duplicates().T\n",
    "D_02_1['year'] = 2002\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2002_3 = deg3_02\n",
    "dict_2002_3['bio_flux'] = bio3_02\n",
    "\n",
    "d_02_3 = {}\n",
    "D_02_3 = {}\n",
    "for key, value in dict_2002_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_02_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_02_3[key] = pd.concat(d_02_3, ignore_index = True)\n",
    "\n",
    "D_02_3 = pd.concat(D_02_3, axis = 1)\n",
    "D_02_3.columns = D_02_3.columns.droplevel()\n",
    "D_02_3 = D_02_3.T.drop_duplicates().T\n",
    "D_02_3['year'] = 2002\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2002_5 = deg5_02\n",
    "dict_2002_5['bio_flux'] = bio5_02\n",
    "\n",
    "d_02_5 = {}\n",
    "D_02_5 = {}\n",
    "for key, value in dict_2002_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_02_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_02_5[key] = pd.concat(d_02_5, ignore_index = True)\n",
    "\n",
    "D_02_5 = pd.concat(D_02_5, axis = 1)\n",
    "D_02_5.columns = D_02_5.columns.droplevel()\n",
    "D_02_5 = D_02_5.T.drop_duplicates().T\n",
    "D_02_5['year'] = 2002\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2002_10 = deg10_02\n",
    "dict_2002_10['bio_flux'] = bio10_02\n",
    "\n",
    "d_02_10 = {}\n",
    "D_02_10 = {}\n",
    "for key, value in dict_2002_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_02_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_02_10[key] = pd.concat(d_02_10, ignore_index = True)\n",
    "\n",
    "D_02_10 = pd.concat(D_02_10, axis = 1)\n",
    "D_02_10.columns = D_02_10.columns.droplevel()\n",
    "D_02_10 = D_02_10.T.drop_duplicates().T\n",
    "D_02_10['year'] = 2002\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2001_1 = deg1_01\n",
    "dict_2001_1['bio_flux'] = bio_01\n",
    "\n",
    "d_01_1 = {}\n",
    "D_01_1 = {}\n",
    "for key, value in dict_2001_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_01_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_01_1[key] = pd.concat(d_01_1, ignore_index = True)\n",
    "\n",
    "D_01_1 = pd.concat(D_01_1, axis = 1)\n",
    "D_01_1.columns = D_01_1.columns.droplevel()\n",
    "D_01_1 = D_01_1.T.drop_duplicates().T\n",
    "D_01_1['year'] = 2001\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2001_3 = deg3_01\n",
    "dict_2001_3['bio_flux'] = bio3_01\n",
    "\n",
    "d_01_3 = {}\n",
    "D_01_3 = {}\n",
    "for key, value in dict_2001_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_01_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_01_3[key] = pd.concat(d_01_3, ignore_index = True)\n",
    "\n",
    "D_01_3 = pd.concat(D_01_3, axis = 1)\n",
    "D_01_3.columns = D_01_3.columns.droplevel()\n",
    "D_01_3 = D_01_3.T.drop_duplicates().T\n",
    "D_01_3['year'] = 2001\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2001_5 = deg5_01\n",
    "dict_2001_5['bio_flux'] = bio5_01\n",
    "\n",
    "d_01_5 = {}\n",
    "D_01_5 = {}\n",
    "for key, value in dict_2001_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_01_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_01_5[key] = pd.concat(d_01_5, ignore_index = True)\n",
    "\n",
    "D_01_5 = pd.concat(D_01_5, axis = 1)\n",
    "D_01_5.columns = D_01_5.columns.droplevel()\n",
    "D_01_5 = D_01_5.T.drop_duplicates().T\n",
    "D_01_5['year'] = 2001\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2001_10 = deg10_01\n",
    "dict_2001_10['bio_flux'] = bio10_01\n",
    "\n",
    "d_01_10 = {}\n",
    "D_01_10 = {}\n",
    "for key, value in dict_2001_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_01_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_01_10[key] = pd.concat(d_01_10, ignore_index = True)\n",
    "\n",
    "D_01_10 = pd.concat(D_01_10, axis = 1)\n",
    "D_01_10.columns = D_01_10.columns.droplevel()\n",
    "D_01_10 = D_01_10.T.drop_duplicates().T\n",
    "D_01_10['year'] = 2001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making yearmonth dfs\n",
    "\n",
    "#1\n",
    "\n",
    "dict_2000_1 = deg1_00\n",
    "dict_2000_1['bio_flux'] = bio_00\n",
    "\n",
    "d_00_1 = {}\n",
    "D_00_1 = {}\n",
    "for key, value in dict_2000_1.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_00_1[month_list[i]] = temp_df\n",
    "    \n",
    "    D_00_1[key] = pd.concat(d_00_1, ignore_index = True)\n",
    "\n",
    "D_00_1 = pd.concat(D_00_1, axis = 1)\n",
    "D_00_1.columns = D_00_1.columns.droplevel()\n",
    "D_00_1 = D_00_1.T.drop_duplicates().T\n",
    "D_00_1['year'] = 2000\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "dict_2000_3 = deg3_00\n",
    "dict_2000_3['bio_flux'] = bio3_00\n",
    "\n",
    "d_00_3 = {}\n",
    "D_00_3 = {}\n",
    "for key, value in dict_2000_3.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_00_3[month_list[i]] = temp_df\n",
    "    \n",
    "    D_00_3[key] = pd.concat(d_00_3, ignore_index = True)\n",
    "\n",
    "D_00_3 = pd.concat(D_00_3, axis = 1)\n",
    "D_00_3.columns = D_00_3.columns.droplevel()\n",
    "D_00_3 = D_00_3.T.drop_duplicates().T\n",
    "D_00_3['year'] = 2000\n",
    "\n",
    "\n",
    "#5\n",
    "\n",
    "dict_2000_5 = deg5_00\n",
    "dict_2000_5['bio_flux'] = bio5_00\n",
    "\n",
    "d_00_5 = {}\n",
    "D_00_5 = {}\n",
    "for key, value in dict_2000_5.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_00_5[month_list[i]] = temp_df\n",
    "    \n",
    "    D_00_5[key] = pd.concat(d_00_5, ignore_index = True)\n",
    "\n",
    "D_00_5 = pd.concat(D_00_5, axis = 1)\n",
    "D_00_5.columns = D_00_5.columns.droplevel()\n",
    "D_00_5 = D_00_5.T.drop_duplicates().T\n",
    "D_00_5['year'] = 2000\n",
    "\n",
    "\n",
    "#10\n",
    "\n",
    "dict_2000_10 = deg10_00\n",
    "dict_2000_10['bio_flux'] = bio10_00\n",
    "\n",
    "d_00_10 = {}\n",
    "D_00_10 = {}\n",
    "for key, value in dict_2000_10.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        mon_arr = value[i,:,:].filled(np.nan).flatten()\n",
    "        mon_arr = mon_arr[~np.isnan(mon_arr)]\n",
    "        temp_df = pd.DataFrame(mon_arr, columns = [key] )\n",
    "        temp_df['month'] = month_list[i]\n",
    "        d_00_10[month_list[i]] = temp_df\n",
    "    \n",
    "    D_00_10[key] = pd.concat(d_00_10, ignore_index = True)\n",
    "\n",
    "D_00_10 = pd.concat(D_00_10, axis = 1)\n",
    "D_00_10.columns = D_00_10.columns.droplevel()\n",
    "D_00_10 = D_00_10.T.drop_duplicates().T\n",
    "D_00_10['year'] = 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearmon_1deg_df = pd.concat([D_00_1,D_01_1,D_02_1,D_03_1,D_04_1,D_05_1,\n",
    "                             D_06_1,D_07_1,D_08_1,D_09_1,D_10_1,D_11_1,\n",
    "                             D_12_1,D_13_1,D_14_1,D_15_1,D_16_1,D_17_1,D_18_1])\n",
    "\n",
    "yearmon_3deg_df = pd.concat([D_00_3,D_01_3,D_02_3,D_03_3,D_04_3,D_05_3,\n",
    "                             D_06_3,D_07_3,D_08_3,D_09_3,D_10_3,D_11_3,\n",
    "                             D_12_3,D_13_3,D_14_3,D_15_3,D_16_3,D_17_3,D_18_3])\n",
    "\n",
    "\n",
    "yearmon_5deg_df = pd.concat([D_00_5,D_01_5,D_02_5,D_03_5,D_04_5,D_05_5,\n",
    "                             D_06_5,D_07_5,D_08_5,D_09_5,D_10_5,D_11_5,\n",
    "                             D_12_5,D_13_5,D_14_5,D_15_5,D_16_5,D_17_5,D_18_5])\n",
    "\n",
    "\n",
    "yearmon_10deg_df = pd.concat([D_00_10,D_01_10,D_02_10,D_03_10,D_04_10,D_05_10,\n",
    "                             D_06_10,D_07_10,D_08_10,D_09_10,D_10_10,D_11_10,\n",
    "                             D_12_10,D_13_10,D_14_10,D_15_10,D_16_10,D_17_10,D_18_10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearmon_1deg_df.to_csv('one_yrmon.csv')\n",
    "yearmon_3deg_df.to_csv('three_yrmon.csv')\n",
    "yearmon_5deg_df.to_csv('five_yrmon.csv')\n",
    "yearmon_10deg_df.to_csv('ten_yrmon.csv')\n",
    "yearmonth_full_df.to_csv('full_yrmon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d3d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving masks\n",
    "np.save('NA_mask_1deg.npy', NA_mask_1deg)\n",
    "np.save('NA_mask_3deg.npy', NA_mask_3deg)\n",
    "np.save('NA_mask_5deg.npy', NA_mask_5deg)\n",
    "np.save('NA_mask_10deg.npy', NA_mask_10deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b92478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd733b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a8c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba9a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77b262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e61878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-ADS_Thesis] *",
   "language": "python",
   "name": "conda-env-conda-ADS_Thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
