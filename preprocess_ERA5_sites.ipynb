{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing ERA5 site data\n",
    "To download the required data, the following era5cli command was used:\n",
    "\n",
    "```\n",
    "era5cli hourly \\\n",
    "    --variables 2m_temperature 2m_dewpoint_temperature surface_net_solar_radiation \\\n",
    "    surface_net_thermal_radiation mean_surface_sensible_heat_flux mean_surface_latent_heat_flux \\\n",
    "    surface_pressure total_precipitation \\\n",
    "    --startyear 1995 --endyear 2020 --levels surface \\\n",
    "    --area 60 -140 15 -55 --overwrite --threads 6\n",
    "```\n",
    "\n",
    "We begin by starting up dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=4, threads_per_worker=2)\n",
    "client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the site extraction function to extract the ERA5 data per site per variable.\n",
    "\n",
    "This preprocessed data is stored in the specified output folder as netCDF files.\n",
    "\n",
    "If you want to add an extra variable or site, not all the data has to be reprocessed: if files already exist they are skipped.\n",
    "This makes it more efficient to explore the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import generate_training_data\n",
    "from pathlib import Path\n",
    "\n",
    "generate_training_data.extract_per_site_era5_data(\n",
    "    preprocessed_ameriflux_data=Path(\"/home/bart/Data/EXCITED/NEE_ameriflux_transcom2.nc\"),\n",
    "    era5_data_folder=Path(\"/media/bart/OS/Data/hourly_era5\"),\n",
    "    output_folder=Path(\"/home/bart/Data/EXCITED/prep_era5\"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing all data, you can continue to training the model!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
